{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2 class=\"sname f-thide sname-max\" data-rid=\"6460\" id=\"artist-name\" title=\"张学友 - Jacky Cheung\">张学友</h2>]\n",
      "['191232', '188432', '189315', '190270', '190449', '188429', '188674', '189396', '190380', '189987', '188647', '190360', '188657', '188703', '188071', '36861904', '188671', '187937', '187672', '188555', '190563', '188989', '189072', '5251209', '190473', '190803', '189313', '189714', '189841', '190328', '190808', '188261', '188747', '190807', '189873', '5251908', '188948', '4875060', '5285096', '189012', '110805', '190452', '187911', '190443', '187966', '188969', '189212', '190372', '187944', '187908']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#获取歌单中所有歌曲id\n",
    "\n",
    "\n",
    "# -*- coding:utf-8 -*-\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#输入歌单url\n",
    "url = 'http://music.163.com/artist?id=' + str(6460)\n",
    "\n",
    "\n",
    "#添加header获取动态网页信息\n",
    "headers = {\"Host\":\" music.163.com\",\n",
    "           \"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36\",\n",
    "           #不必要的header属性可能会影响响应报文的编码方式，所以把它们注释掉#\n",
    "           \"Accept\":\" text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "           #\"Accept-Language\":\" zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3\",\n",
    "           #\"Referer\":\"http://music.163.com/\",\n",
    "           #\"Cookie\": \"JSESSIONID-WYYY=k52%2FPjMyNbX0v38jH2efUXwEIZpw2NagEUzwTX%2FgifMsoMswU6yo3NN%5C%2Bb9jCpsRFZIc6lvPUK9wEjgBzwM%2B1T%2FRyvRGHhqyWbdvEcugCbNqTihfxHK1el66fk%2BNntcSwGVOBMEwlcFDBusingcH76NIeAQwbC6h%5CcipxCdO8T5IfBVO%3A1510825875526; _iuqxldmzr_=32; _ntes_nnid=e5ec3ba6b841b9d3eadcb910066f4dcb,1510815153893; _ntes_nuid=e5ec3ba6b841b9d3eadcb910066f4dcb; __utma=94650624.1386008069.1510815154.1510815154.1510824076.2; __utmz=94650624.1510815154.1.1.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; __utmb=94650624.2.10.1510824076; __utmc=94650624\",\n",
    "           #\"Connection\": \"keep-alive\",\n",
    "           #\"Upgrade-Insecure-Requests\": \"1\"\n",
    "          }\n",
    "\n",
    "\n",
    "#只传url不能获得响应，需要传header\n",
    "request = urllib.request.Request(url,headers=headers)\n",
    "response = urllib.request.urlopen(request)\n",
    "#不decode的话text是十六进制，不是中文\n",
    "html = response.read().decode('utf-8','ignore')\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "#print(\"html:\",html)\n",
    "#print(\"soup:\",soup)\n",
    "\n",
    "#web_data = requests.get(singer_url,headers = headers)\n",
    "#print(web_data.text)\n",
    "#soup = BeautifulSoup(soup, 'lxml')\n",
    "#print(web_data)\n",
    "#print(web_data.text)\n",
    "singer_name = soup.select(\"#artist-name\")\n",
    "print(singer_name)\n",
    "r = soup.find('ul', {'class': 'f-hide'}).find_all('a')\n",
    "r = (list(r))\n",
    "music_id_set=[]\n",
    "for each in r:\n",
    "    song_name = each.text  # print(each.text)\n",
    "    song_id = each.attrs[\"href\"]\n",
    "    music_id_set.append(song_id[9:])\n",
    "print(music_id_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作曲 : 周杰伦\n",
      " 作词 : 周杰伦\n",
      "Jay：你住的  巷子里  我租了一间公寓\n",
      "为了想与你不期而遇\n",
      "高中三年  我为什么  为什么不好好读书\n",
      "没考上跟你一样的大学\n",
      "我找了份工作  离你宿舍很近\n",
      "当我开始学会做蛋饼  才发现你  不吃早餐\n",
      "喔  你又擦肩而过\n",
      "你耳机听什么  能不能告诉我\n",
      "\n",
      "合：躺在你学校的操场看星空\n",
      "教室里的灯还亮着你没走\n",
      "记得  我写给你的情书\n",
      "都什么年代了\n",
      "到现在我还在写着\n",
      "\n",
      "总有一天总有一年会发现\n",
      "有人默默的陪在你的身边\n",
      "也许  我不该在你的世界\n",
      "当你收到情书\n",
      "也代表我已经走远\n",
      "\n",
      "Gary：学校旁  的广场  我在这等钟声响\n",
      "等你下课一起走好吗\n",
      "Jay：弹着琴  唱你爱的歌  暗恋一点都不痛苦\n",
      "（Gary：一点都不痛苦）\n",
      "Jay：痛苦的是你\n",
      "合：根本没看我\n",
      "\n",
      "Jay：我唱这么走心  却走不进你心里\n",
      "（Gary：这么走心  进你心里）\n",
      "Jay：在人来人往\n",
      "合：找寻着你  守护着你  不求结局\n",
      "Gary：喔  你又擦肩而过\n",
      "（Jay：喔  而过）\n",
      "Jay：我唱告白气球  终于你回了头\n",
      "\n",
      "合：躺在你学校的操场看星空\n",
      "教室里的灯还亮着你没走\n",
      "记得  我写给你的情书\n",
      "都什么年代了\n",
      "到现在我还在写着\n",
      "\n",
      "总有一天总有一年会发现\n",
      "有人默默的陪在你的身边\n",
      "也许  我不该在你的世界\n",
      "当你收到情书\n",
      "也代表我已经走远\n"
     ]
    }
   ],
   "source": [
    "#根据歌词id提取歌词\n",
    "\n",
    "lrc_url = 'http://music.163.com/api/song/lyric?' + 'id=' + str(531051217) + '&lv=1&kv=1&tv=-1'\n",
    "lyric = requests.get(lrc_url)\n",
    "json_obj = lyric.text\n",
    "j = json.loads(json_obj)\n",
    "lrc = j['lrc']['lyric']\n",
    "pat = re.compile(r'\\[.*\\]')\n",
    "lrc = re.sub(pat, \"\", lrc)\n",
    "lrc = lrc.strip()\n",
    "print(lrc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#一次性爬取网易云音乐我的歌单里面所有歌曲的歌词\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import urllib\n",
    "from bs4 import *\n",
    "url = \"http://music.163.com/playlist?id=63306090\"\n",
    "headers = {\"Host\":\" music.163.com\",\n",
    "           \"User-Agent\":\" Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:56.0) Gecko/20100101 Firefox/56.0\",\n",
    "           #不必要的header属性可能会影响响应报文的编码方式，所以把它们注释掉#\n",
    "           \"Accept\":\" text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "           #\"Accept-Language\":\" zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3\",\n",
    "           #\"Referer\":\"http://music.163.com/\",\n",
    "           #\"Cookie\": \"JSESSIONID-WYYY=k52%2FPjMyNbX0v38jH2efUXwEIZpw2NagEUzwTX%2FgifMsoMswU6yo3NN%5C%2Bb9jCpsRFZIc6lvPUK9wEjgBzwM%2B1T%2FRyvRGHhqyWbdvEcugCbNqTihfxHK1el66fk%2BNntcSwGVOBMEwlcFDBusingcH76NIeAQwbC6h%5CcipxCdO8T5IfBVO%3A1510825875526; _iuqxldmzr_=32; _ntes_nnid=e5ec3ba6b841b9d3eadcb910066f4dcb,1510815153893; _ntes_nuid=e5ec3ba6b841b9d3eadcb910066f4dcb; __utma=94650624.1386008069.1510815154.1510815154.1510824076.2; __utmz=94650624.1510815154.1.1.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; __utmb=94650624.2.10.1510824076; __utmc=94650624\",\n",
    "           #\"Connection\": \"keep-alive\",\n",
    "           #\"Upgrade-Insecure-Requests\": \"1\"\n",
    "          }\n",
    "#只传url不能获得响应，需要传header\n",
    "request = urllib.request.Request(url,headers=headers)\n",
    "response = urllib.request.urlopen(request)\n",
    "#不decode的话text是十六进制，不是中文\n",
    "html = response.read().decode('utf-8','ignore')\n",
    "soup = BeautifulSoup(html)\n",
    "#打开1.txt 把歌单中的歌词写入\n",
    "f=open('lx_songlist.txt','w',encoding='utf-8')\n",
    "for item in soup.ul.children:\n",
    "    #取出歌单里歌曲的id  形式为：/song?id=11111111    \n",
    "    song_id = item('a')[0].get(\"href\",None)\n",
    "    #利用正则表达式提取出song_id的数字部分sid    \n",
    "    pat = re.compile(r'[0-9].*$')\n",
    "    sid = re.findall(pat,song_id)[0]\n",
    "    #这里的url是真实的歌词页面\n",
    "    url = \"http://music.163.com/api/song/lyric?\"+\"id=\"+str(sid)+\"&lv=1&kv=1&tv=-1\"\n",
    "    html = requests.post(url)\n",
    "    json_obj = html.text\n",
    "    #歌词是一个json对象 解析它    \n",
    "    j = json.loads(json_obj)\n",
    "    try:\n",
    "        lyric = j['lrc']['lyric']\n",
    "    except KeyError:\n",
    "        lyric = \"无歌词\"\n",
    "    pat = re.compile(r'\\[.*\\]')\n",
    "    lrc = re.sub(pat,\"\",lyric)\n",
    "    lrc = lrc.strip()\n",
    "    #print(lrc)    \n",
    "    f.write(lrc)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
